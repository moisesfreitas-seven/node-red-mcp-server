# Node-RED MCP Server 

Conecta Node-RED a LLMs via Model Context Protocol (MCP) para fluxos de IA inteligentes.

[![Deploy on Railway](https://railway.app/button.svg)](https://railway.com/deploy/node-red-mcp)

> **ğŸš€ Template pronto para deploy no Railway** - Node-RED configurado com MCP (Model Context Protocol) para integraÃ§Ã£o com LLMs

[ğŸ‡ºğŸ‡¸ Read in English](README.md)

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto contÃ©m uma estrutura Docker com dois containers principais que integram o Node-RED e o mcp-host para rodar o MCP Server (Model Context Protocol). O objetivo Ã© permitir que fluxos no Node-RED possam interagir com modelos LLM como o GPT-4 da OpenAI, usando um servidor MCP.

Essa primeira versÃ£o suporta somente o modelo GPT-4 da OpenAI.

VocÃª consegue rodar um MCP local e remoto.
Exemplo de um MCP remoto:

```bash
npx -y @smithery/cli@latest run @nickclyde/duckduckgo-mcp-server --key sua-chave-do-smithery
```

[ğŸ”— Encontre outros MCPs no smithery.io](https://smithery.io)

## ğŸš€ Templates Prontos para Deploy

### Node-RED MCP Template para Railway

Para facilitar o deploy e comeÃ§ar rapidamente, criamos um template otimizado para o Railway:

**[ğŸ“‹ Ver Template Completo](node-red-docker/README.md)**

**CaracterÃ­sticas do Template:**
- âœ… **Deploy com um clique** no Railway
- âœ… **Node-RED 4.0.0** prÃ©-configurado
- âœ… **MCP Tools Node** jÃ¡ instalado
- âœ… **ConfiguraÃ§Ã£o automÃ¡tica** via variÃ¡veis de ambiente
- âœ… **Backup automÃ¡tico** de fluxos e configuraÃ§Ãµes
- âœ… **Monitoramento** integrado

**Como usar:**
1. Acesse o [README do Template](node-red-docker/README.md)
2. Clique no botÃ£o "Deploy on Railway"
3. Configure suas variÃ¡veis de ambiente
4. Pronto! Node-RED rodando na nuvem

---

## â–¶ï¸ Como Executar

### Passos para rodar o projeto via Docker Compose:

1. **Clone este repositÃ³rio:**
   ```bash
   git clone https://github.com/moises-paschoalick/node-red-mcp-server
   cd node-red-docker
   docker compose up -d
   ```

2. **Abra o projeto em:** http://localhost:1899/

3. **Instale o node mcp-tools**
   Para isso precisamos ter o node mcp-tools, instalar o node-red-contrib-mcp-tools na UI do Node-RED.

   **OpÃ§Ãµes -> Gerenciar Paleta**
   **Instalar node-red-contrib-mcp-tools**
   [Imagem instalaÃ§Ã£o]

   [link do node-red-contrib-mcp-tools]
   link do projeto npm

4. **Configure o componente com a chave da OpenAI**
   [imagem do componente]

## ğŸ§± Estrutura dos Containers

- **`mcp-host`**  
  Componente feito em Node.js que faz a ponte (bridge) entre o Node-RED (via componente `mcp-tools`) e os MCP Servers.  
  Ele Ã© responsÃ¡vel por intermediar a comunicaÃ§Ã£o entre o `mcp-client` (modelo LLM) e o `mcp-server` (entende a implementaÃ§Ã£o das tools).

- **`mcp-server-demo`** (Node-RED)  
  ContÃ©m o ambiente do Node-RED jÃ¡ configurado para se comunicar com o `mcp-host` usando o componente `mcp-tools`. Ã‰ um exemplo de um mcp-server feito em NodeJS para testar e verificar se o ambiente estÃ¡ funcional.

> **Importante**: no componente **mcp-tools** dentro do Node-RED, Ã© necessÃ¡rio configurar a URL do MCP Host como:
> ```
> http://mcp-host:3000
> ```

---

## ğŸ“¦ Componentes

- **`mcp-host`**
  - Recebe chamadas do Node-RED via `mcp-tools`
  - Redireciona a solicitaÃ§Ã£o para o `mcp-client`
  - Encaminha o resultado para o `mcp-server` (local ou remoto)
  
- **`mcp-client`**
  - Realiza a comunicaÃ§Ã£o com um modelo de linguagem (LLM)
  - Atualmente usa o modelo `gpt-4o` da OpenAI
  - Pode ser modificado para usar outros modelos no futuro (ex: Claude, Gemini, LLaMA)

- **`mcp-server-demo`**
  - Um exemplo funcional de MCP Server rodando localmente
  - ContÃ©m "tools" (ferramentas) que podem ser chamadas pelo modelo, como:
    - **Hello Tool**: responde com "Hello World"
    - **Local Time**: retorna a hora local do servidor
    - **Weather Tool**: consulta clima atual de SÃ£o Paulo via `wttr.in`

---

### PrÃ©-requisitos

- Docker
- Docker Compose

### Endpoints para verificar a integridade no mcp-host 
http://localhost:3000/health

## Arquitetura

```
Node-RED Component â†’ mcp-host (Express.js) â†’ mcp-client â†’ mcp-server
                                                â†“
                                           OpenAI API
```

### Componentes Detalhados

#### 1. **mcp-host** (Servidor Web)
- **LocalizaÃ§Ã£o:** `/mcp-host/`
- **FunÃ§Ã£o:** Servidor Express.js que orquestra as comunicaÃ§Ãµes
- **Porta:** 3000 (configurÃ¡vel)
- **Endpoints:**
  - `POST /execute` - Executa prompts
  - `GET /health` - Status do servidor
  - `GET /tools` - Lista ferramentas disponÃ­veis
  - `POST /disconnect` - Desconecta sessÃµes

#### 2. **mcp-client** (Cliente MCP)
- **LocalizaÃ§Ã£o:** `/mcp-client/`
- **FunÃ§Ã£o:** Classe que gerencia conexÃµes com servidores MCP e OpenAI
- **Recursos:**
  - ConexÃ£o/desconexÃ£o automÃ¡tica
  - Gerenciamento de sessÃµes
  - ConversÃ£o de ferramentas MCP para formato OpenAI
  - ExecuÃ§Ã£o de prompts com tool calling

#### 3. **mcp-server** (Servidor MCP)
- **LocalizaÃ§Ã£o:** `/mcp-server/`
- **FunÃ§Ã£o:** ImplementaÃ§Ã£o do servidor MCP com ferramentas e recursos
- **Ferramentas incluÃ­das:**
  - Hello Tool (exemplo)
  - Users Tool (API externa)
  - Textract Tool (anÃ¡lise de imagens)

#### 4. **node-red-mcp-component** (Componente Node-RED)
- **LocalizaÃ§Ã£o:** `/node-red-mcp-component/`
- **FunÃ§Ã£o:** NÃ³ customizÃ¡vel para Node-RED
- **ConfiguraÃ§Ãµes:**
  - URL do MCP Host
  - API Key da OpenAI
  - Comando do servidor MCP
  - Argumentos do servidor MCP
  - Session ID
  - Timeout

## Endpoints da API

### POST /execute

Executa um prompt atravÃ©s do agente MCP.

**Corpo da RequisiÃ§Ã£o:**
```json
{
  "prompt": "show hello world message",
  "apiKey": "sk-sua-chave-aqui",
  "serverCommand": "node",
  "serverArgs": ["../mcp-server/build/index.js"],
  "sessionId": "default"
}
```

**Resposta:**
```json
{
  "success": true,
  "response": "Hello, World! This is a tool response!",
  "toolsUsed": [...],
  "messages": [...]
}
```

### GET /health

Verifica o status do servidor.

**Resposta:**
```json
{
  "status": "ok",
  "timestamp": "2025-06-11T23:32:04.612Z",
  "activeClients": 0
}
```

### GET /tools

Lista ferramentas disponÃ­veis.

**ParÃ¢metros de Query:**
- `apiKey` - API Key da OpenAI
- `serverCommand` - Comando do servidor MCP
- `serverArgs` - Argumentos do servidor MCP

## InstalaÃ§Ã£o e ConfiguraÃ§Ã£o (sem Docker)

### 1. Preparar os Componentes

```bash
# Instalar dependÃªncias do mcp-server
cd mcp-server
npm install
npm run build

# Instalar dependÃªncias do mcp-client
cd ../mcp-client
npm install
npm run build

# Instalar dependÃªncias do mcp-host
cd ../mcp-host
npm install
```

### 2. Iniciar o MCP Host

```bash
cd mcp-host
npm start
```

O servidor rodarÃ¡ na porta 3000.

## ğŸ› SoluÃ§Ã£o de Problemas

### Problemas Comuns

#### 1. Container nÃ£o inicia
```bash
# Verifique os logs
docker logs node-red-mcp

# Verifique se as portas estÃ£o disponÃ­veis
netstat -tulpn | grep :1899
```

#### 2. MCP Tools nÃ£o funciona
- Verifique se a API Key da OpenAI estÃ¡ correta
- Confirme se o MCP Host estÃ¡ acessÃ­vel
- Verifique os logs do MCP Host

#### 3. Erro de permissÃµes
```bash
# Corrija as permissÃµes
docker exec -it node-red-mcp chown -R node-red:node-red /data
```

### Logs e Debug

```bash
# Logs do Node-RED
docker logs -f node-red-mcp

# Logs do MCP Host
docker logs -f mcp-host

# Acesse os logs via interface web
# http://localhost:1899/admin/logs
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente

| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o | ObrigatÃ³rio |
|----------|-----------|--------|-------------|
| `ADMIN_PASSWORD` | Senha do admin do Node-RED | `admin123` | âœ… |
| `NODE_RED_ENABLE_PROJECTS` | Habilitar projetos | `false` | âŒ |
| `OPENAI_API_KEY` | Chave da API OpenAI | - | âŒ |

### Portas

- **1899**: Interface web do Node-RED
- **3000**: MCP Host API

### Volumes

- `/data`: Dados persistentes do Node-RED
  - Fluxos e configuraÃ§Ãµes
  - Node modules customizados
  - Logs e backups

## ğŸ“š Exemplos de Uso

### Exemplo 1: Chatbot Simples

```javascript
// Fluxo bÃ¡sico de chatbot
[
  {
    "id": "chatbot-flow",
    "type": "tab",
    "label": "Chatbot Example",
    "nodes": [
      {
        "id": "trigger",
        "type": "inject",
        "name": "Start Chat",
        "props": {
          "payload": "OlÃ¡, como vocÃª pode me ajudar?"
        }
      },
      {
        "id": "mcp-tools",
        "type": "mcp-tools",
        "name": "AI Response",
        "config": {
          "prompt": "{{payload}}",
          "apiKey": "{{env.OPENAI_API_KEY}}"
        }
      },
      {
        "id": "debug",
        "type": "debug",
        "name": "Show Response"
      }
    ]
  }
]
```

### Exemplo 2: AnÃ¡lise de Dados

```javascript
// Fluxo para anÃ¡lise de dados com LLM
[
  {
    "id": "data-analysis",
    "type": "tab",
    "label": "Data Analysis",
    "nodes": [
      {
        "id": "data-input",
        "type": "inject",
        "name": "Input Data",
        "props": {
          "payload": {
            "temperature": 25,
            "humidity": 60,
            "pressure": 1013
          }
        }
      },
      {
        "id": "analysis",
        "type": "mcp-tools",
        "name": "Analyze Data",
        "config": {
          "prompt": "Analise estes dados meteorolÃ³gicos: {{JSON.stringify(payload)}}"
        }
      }
    ]
  }
]
```

## ğŸ”— IntegraÃ§Ãµes

### MCP Servers Suportados

- **Local MCP Server**: IncluÃ­do no projeto
- **Remote MCP Servers**: Via Smithery.io
- **Custom MCP Servers**: Sua prÃ³pria implementaÃ§Ã£o

### LLMs Suportados

- **OpenAI GPT-4**: ConfiguraÃ§Ã£o padrÃ£o
- **OpenAI GPT-3.5**: Suportado
- **Claude**: Via configuraÃ§Ã£o customizada
- **Outros**: Via adaptadores MCP

## ğŸ“ˆ Monitoramento

### MÃ©tricas DisponÃ­veis

- **CPU Usage**: Via Docker stats
- **Memory Usage**: Via Docker stats
- **Network Traffic**: Via Docker stats
- **Application Logs**: Via Docker logs

### Alertas

Configure alertas para:
- Uso de CPU > 80%
- Uso de memÃ³ria > 80%
- Erros de aplicaÃ§Ã£o
- Tempo de resposta > 5s

## ğŸ”„ Backup e Restore

### Backup AutomÃ¡tico

Para backup manual:

```bash
# Backup dos dados
docker exec node-red-mcp tar -czf /tmp/backup.tar.gz /data

# Download do backup
docker cp node-red-mcp:/tmp/backup.tar.gz ./backup.tar.gz
```

### Restore

```bash
# Upload do backup
docker cp ./backup.tar.gz node-red-mcp:/tmp/

# Restore dos dados
docker exec node-red-mcp tar -xzf /tmp/backup.tar.gz -C /
```

## ğŸ¤ ContribuiÃ§Ã£o

1. **Fork** o projeto
2. **Crie uma branch** para sua feature (`git checkout -b feature/NovaFuncionalidade`)
3. **Commit** suas mudanÃ§as (`git commit -m 'Adiciona nova funcionalidade'`)
4. **Push** para a branch (`git push origin feature/NovaFuncionalidade`)
5. **Abra um Pull Request**

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ†˜ Suporte

### Canais de Ajuda

- **ğŸ“§ Email**: [seu-email@exemplo.com](mailto:seu-email@exemplo.com)
- **ğŸ› Issues**: [GitHub Issues](https://github.com/moises-paschoalick/node-red-mcp-server/issues)
- **ğŸ’¬ Discord**: [Link do Discord](https://discord.gg/seu-servidor)
- **ğŸ“– Wiki**: [DocumentaÃ§Ã£o Wiki](https://github.com/moises-paschoalick/node-red-mcp-server/wiki)

### Recursos Ãšteis

- [Node-RED Documentation](https://nodered.org/docs/)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [Railway Documentation](https://docs.railway.app/)
- [OpenAI API Documentation](https://platform.openai.com/docs/)

## ğŸ™ Agradecimentos

- [Node-RED](https://nodered.org/) - Plataforma de programaÃ§Ã£o visual
- [Railway](https://railway.app/) - Plataforma de deploy
- [OpenAI](https://openai.com/) - Modelos de linguagem
- [MCP Community](https://modelcontextprotocol.io/) - Protocolo MCP

---

**â­ Se este projeto foi Ãºtil, considere dar uma estrela no repositÃ³rio!** 